ğŸ§  Day 13 â€“ Two Pointer + Naive Bayes:

ğŸ“Œ SLOT 1: Two Pointer Technique (DSA):

1ï¸âƒ£ What is Two Pointer Technique?
Definition: Two Pointer technique is a problem-solving method where we use two indexes (pointers) to traverse an array or string.

ğŸ‘‰ Simple words:
Ek left se chalega, ek right se chalega.
Instead of nested loops (O(nÂ²)),
we reduce it to O(n).

2ï¸âƒ£ When to Use It?
Use when:
Array is sorted
Pair sum problems
Reverse problems
Remove duplicates
Compare elements from both ends

3ï¸âƒ£ Left & Right Pointer Concept
Imagine:

arr = [1, 2, 3, 4, 5]
       L           R
L = 0
R = last index
We move:
L â†’ forward
R â†’ backward

4ï¸âƒ£ Time Complexity Idea
Without two pointer: O(nÂ²)
With two pointer: O(n)
ğŸ‘‰ Faster. Cleaner. Efficient.
ğŸ”¥ Example 1: Reverse Array Using Two Pointers
Python
arr = [1, 2, 3, 4, 5]

left = 0
right = len(arr) - 1

while left < right:
    arr[left], arr[right] = arr[right], arr[left]
    left += 1
    right -= 1

print(arr)
Output:

[5, 4, 3, 2, 1]
âœ… Practice Question 1:
If array = [10, 20, 30],
after reversing, what will be output?
ğŸ”¥ Example 2: Pair With Given Sum (Sorted Array)
Python
arr = [1, 2, 4, 6, 8]
target = 10

left = 0
right = len(arr) - 1

while left < right:
    s = arr[left] + arr[right]

    if s == target:
        print("Pair Found:", arr[left], arr[right])
        break
    elif s < target:
        left += 1
    else:
        right -= 1

âœ… Practice Question 2:
Why must array be sorted in this method?
ğŸ”¥ Example 3: Remove Duplicates (Sorted Array)
Python
arr = [1,1,2,2,3,4,4]
result = []

left = 0

while left < len(arr):
    if arr[left] not in result:
        result.append(arr[left])
    left += 1

print(result)
Better optimized version exists, but this is beginner friendly.

ğŸ“Œ SLOT 2: Naive Bayes (Machine Learning)

1ï¸âƒ£ What is Naive Bayes?
Naive Bayes is a classification algorithm based on probability.
ğŸ‘‰ It predicts class using probability.
Used in:
Spam detection
Sentiment analysis
Text classification

2ï¸âƒ£ Bayes Theorem (Basic Idea)
Formula:

P(A|B) = (P(B|A) * P(A)) / P(B)
Don't panic.
Simple meaning:
Posterior = (Likelihood Ã— Prior) / Evidence

3ï¸âƒ£ Prior & Posterior
Prior â†’ Probability before seeing data
Posterior â†’ Probability after seeing data
Example:
If 70% emails are spam â†’ Prior
After seeing word "Free" â†’ Posterior changes

4ï¸âƒ£ Why Called "Naive"?
Because it assumes:
All features are independent.
Which is not always true.
But works surprisingly well.

5ï¸âƒ£ Spam Detection Example
Dataset:
Message
Label
Free money
Spam
Hi friend
Not Spam
Win cash
Spam

ğŸ”¥ Train Naive Bayes Model
Python
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB

texts = ["Free money", "Hi friend", "Win cash"]
labels = [1, 0, 1]   # 1 = Spam, 0 = Not Spam

vectorizer = CountVectorizer()
X = vectorizer.fit_transform(texts)

model = MultinomialNB()
model.fit(X, labels)

new_text = ["Free cash"]
new_X = vectorizer.transform(new_text)

prediction = model.predict(new_X)

print(prediction)

âœ… Practice Question 3:
Why is Naive Bayes good for text data?

ğŸ” Quick Revision
Two Pointer:
Two indexes
O(n)
Good for sorted arrays
Naive Bayes:
Based on probability
Used for classification
Day 13 complete ğŸ˜
Assumes feature independence
ğŸ§  Now Tell Me:
What is time complexity of two pointer method?
What is Prior probability?
Why is it called Naive?
Answer these first.
Fir next level questions karenge ğŸ’ª
