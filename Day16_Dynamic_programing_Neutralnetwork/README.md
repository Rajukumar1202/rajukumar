ğŸ§  Day 16 â€“ Dynamic Programming & Neural Network (DSA + AIML):

ğŸ“Œ SLOT 01: Dynamic Programming Basics (DSA):

1ï¸âƒ£ What is Dynamic Programming?
Dynamic Programming (DP) is a problem-solving technique where a complex problem is divided into smaller subproblems, and the results of those subproblems are stored to avoid repeated computation.
ğŸ‘‰ Simple idea:
Solve once â†’ Store â†’ Reuse

2ï¸âƒ£ Overlapping Subproblems
Overlapping subproblems occur when the same subproblem is solved multiple times in recursion.
Example:
In Fibonacci recursion, values like F(3), F(2) are computed again and again.
ğŸ‘‰ DP stores these values to improve efficiency.

3ï¸âƒ£ Optimal Substructure
A problem has optimal substructure if its optimal solution can be constructed from optimal solutions of its smaller subproblems.
Example:
Shortest path problem â€” shortest path from A to C uses shortest path from A to B.

4ï¸âƒ£ Memoization vs Tabulation

âœ… Memoization (Top-Down)
Uses recursion
Stores results in memory (dictionary/array)
Computes only when needed
âœ… Tabulation (Bottom-Up)
Uses iteration (loops)
Builds table from smallest to largest problem
No recursion
ğŸ‘‰ Key difference:
Memoization â†’ recursion based
Tabulation â†’ loop based

5ï¸âƒ£ Example â€” Fibonacci using Memoization
Python
dp = {}

def fib(n):
    if n <= 1:
        return n
    if n in dp:
        return dp[n]
    dp[n] = fib(n-1) + fib(n-2)
    return dp[n]

print(fib(6))

6ï¸âƒ£ Climbing Stairs Problem
A person can climb 1 or 2 steps at a time.
Ways(n) = Ways(n-1) + Ways(n-2)
ğŸ‘‰ Same pattern as Fibonacci

ğŸ“Œ SLOT 02: Neural Network Introduction (AIML):

1ï¸âƒ£ What is a Neural Network?
A Neural Network is a machine learning model inspired by the human brain, consisting of interconnected neurons that process information and make predictions.
ğŸ‘‰ Used in image recognition, speech, NLP, etc.

2ï¸âƒ£ Layers in Neural Network
âœ… Input Layer
Receives input features
âœ… Hidden Layer
Performs computations and feature transformation
âœ… Output Layer
Produces final prediction
ğŸ‘‰ Flow:
Input â†’ Hidden â†’ Output

3ï¸âƒ£ What is a Neuron?
A neuron is the basic unit of a neural network that:
takes inputs
multiplies with weights
applies activation
produces output
ğŸ‘‰ Acts like a small calculator.

4ï¸âƒ£ Why Neural Networks are Powerful?
Can learn complex patterns
Works well for non-linear problems
Handles large datasets
Widely used in deep learning

5ï¸âƒ£ Activation Function (Basic Idea)
Activation function determines whether a neuron should activate or not.
Common examples:
ReLU
Sigmoid
Tanh
ğŸ‘‰ Purpose: add non-linearity and control output.

ğŸ” Quick Revision
ğŸ‘‰DP â†’ solve subproblems + store results
ğŸ‘‰Overlapping â†’ repeated computation
ğŸ‘‰Optimal substructure â†’ build solution from smaller solutions
ğŸ‘‰Memoization â†’ recursion + memory
ğŸ‘‰Tabulation â†’ loop + table
ğŸ‘‰Neural Network â†’ brain-inspired model
ğŸ‘‰Layers â†’ input, hidden, output
ğŸ‘‰Neuron â†’ basic processing unit
ğŸ‘‰Activation â†’ controls neuron output

ğŸ’» Coding Practice with Solution
âœ… 1. Fibonacci using DP (Memoization)
Python
dp = {}

def fib(n):
    if n <= 1:
        return n
    if n in dp:
        return dp[n]
    dp[n] = fib(n-1) + fib(n-2)
    return dp[n]

print(fib(6))
âœ… 2. Climbing Stairs
Python
def climb(n):
    if n <= 2:
        return n
    dp = [0]*(n+1)
    dp[1], dp[2] = 1, 2

    for i in range(3, n+1):
        dp[i] = dp[i-1] + dp[i-2]

    return dp[n]

print(climb(4))
âœ… 3. Fibonacci using Tabulation
Python
def fib_tab(n):
    dp = [0]*(n+1)
    dp[1] = 1

    for i in range(2, n+1):
        dp[i] = dp[i-1] + dp[i-2]

    return dp

print(fib_tab(5))

Day 16 complete âœ…ğŸš€ğŸ˜(âÂ´â—¡`â)
