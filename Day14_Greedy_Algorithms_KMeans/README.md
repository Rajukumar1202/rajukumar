ğŸ§  Day 14 â€“ Greedy Algorithms & K-Means Clustering (DSA + ML):

ğŸ“Œ SLOT 01: Greedy Algorithms (DSA):

1ï¸âƒ£ What is Greedy Algorithm?

A Greedy Algorithm is an approach where we choose the best option at the current step to get an overall optimal solution.

ğŸ‘‰ Simple words:
Har step par best choice karo â†’ final answer mil jayega.

Example idea:
Agar tum shortest time me kaam complete karna chahte ho â†’ har time smallest task pehle karoge.

2ï¸âƒ£ Greedy Choice Property

Meaning:
Problem aisi honi chahiye jahan local best choice â†’ global best result de.
ğŸ‘‰ Har greedy problem me ye property hoti hai.

3ï¸âƒ£ When Greedy Works and When Fails

âœ… Works:

Activity Selection

Fractional Knapsack

Minimum coins (some cases)

âŒ Fails:

0/1 Knapsack

Some coin systems

ğŸ‘‰ Kyuki local best â†’ global best nahi deta.

4ï¸âƒ£ Greedy vs Dynamic Programming (Basic)
Greedy	Dynamic Programming
Local best choice	All possibilities check
Fast	Slower
Simple	Complex
Not always optimal	Always optimal

ğŸ‘‰ Memory trick:
Greedy = shortcut
DP = full calculation

5ï¸âƒ£ Example â€“ Coin Change (Basic Greedy)

Goal: minimum coins use karna.

Coins: 10, 5, 1
Amount: 16

ğŸ‘‰ 10 + 5 + 1 = 3 coins

Greedy â†’ largest coin first.

6ï¸âƒ£ Activity Selection Problem

Goal: maximum activities select karna without overlap.

ğŸ‘‰ Activity ko finish time ke basis par sort karo
ğŸ‘‰ Earliest finish wali choose karo

ğŸ‘‰ Greedy working example.

7ï¸âƒ£ Fractional Knapsack Concept

ğŸ‘‰ Item ko fraction me le sakte ho
ğŸ‘‰ Highest value/weight ratio wala item first

ğŸ‘‰ Greedy works âœ”

ğŸ”¥ Practice Question

Why greedy fails in 0/1 knapsack?

ğŸ“Œ SLOT 02: K-Means Clustering (Machine Learning):

1ï¸âƒ£ Recap â€“ What is Clustering?

Clustering = similar data ko group karna.

ğŸ‘‰ Example: customer groups

2ï¸âƒ£ What is K-Means?

K-Means is an unsupervised ML algorithm that divides data into K clusters.

ğŸ‘‰ K = number of groups

3ï¸âƒ£ How K-Means Works (Step-by-Step)

ğŸ‘‰Choose K
ğŸ‘‰Select random centroids
ğŸ‘‰Assign points to nearest centroid
ğŸ‘‰Update centroid
ğŸ‘‰Repeat until stable
ğŸ‘‰ Ye loop hi K-Means ka core hai.

4ï¸âƒ£ Choosing Value of K (Elbow Method)

Idea:
Different K try karo â†’ error plot karo

ğŸ‘‰ Jahan curve bend kare â†’ best K

ğŸ‘‰ Isko elbow bolte hain.

5ï¸âƒ£ Mini Example â€“ Apply K-Means
from sklearn.cluster import KMeans
import numpy as np

data = np.array([[1,2],[1,4],[1,0],[10,2],[10,4],[10,0]])

model = KMeans(n_clusters=2)
model.fit(data)

print(model.labels_)


ğŸ‘‰ Output â†’ cluster labels

6ï¸âƒ£ Visualization of Clusters
import matplotlib.pyplot as plt

plt.scatter(data[:,0], data[:,1], c=model.labels_)
plt.show()


ğŸ‘‰ Scatter me clusters dikhenge.

ğŸ”¥ Practice Question

What happens if K is chosen too large?

ğŸ” Quick Revision

1ï¸âƒ£Greedy â†’ local best choice

2ï¸âƒ£Works only when greedy property holds

3ï¸âƒ£Activity selection â†’ greedy example

4ï¸âƒ£K-Means â†’ clustering algorithm

5ï¸âƒ£Steps â†’ assign â†’ update â†’ repeat

6ï¸âƒ£Elbow â†’ best K selection

âœ… Status

Day 14 Completed Successfully ğŸ’¯
